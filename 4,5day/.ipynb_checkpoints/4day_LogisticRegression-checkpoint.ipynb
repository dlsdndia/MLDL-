{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 비용 함수( Cost Function )\n",
    "\n",
    "- 로지스틱 회귀 또한 경사 하강법을 사용하여 가중치 W( weight )와 편향 b( bias )를 찾아내지만, 비용 함수로는 평균 제곱 오차( MSE )를 사용하지 않는다.\n",
    "- 그 이유는 시그모이드 함수에 비용 함수를 평균 제곱 오차( MSE )로 하여 그래프를 그리면 다음과 비슷한 형태가 되기 때문이다.\n",
    "\n",
    "![Alt text]( localmimum.png )\n",
    "\n",
    "- 로지스틱 회귀에서 평균 제곱 오차( MSE )를 비용 함수로 사용하면 경사 하강법을 사용하였을때 자칫 잘못하면 찾고자 하는 최소값이 아니 잘못된 최소값에 빠질 수 있다.\n",
    "- 이를 글로별 미니멈( global minimum )이 아닌 특정 구역에서의 최소값인 로컬 미니멈( local minimum )에 도달했다고 한다.\n",
    "- 이는 cost가 최소가 되는 가중치 W( weight )와 편향 b( bias )를 찾는다는 비용 함수의 목적에 맞지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "    J( W ) = \\frac{1}{n}\\sum_{i=1}^nf(H(x^{(i)}),y^{(i)})\n",
    "\\end{equation*}\n",
    "\n",
    "- 위의 식에서 샘플 데이터의 개수가 n개이고, 어떤 함수 f가 실제값 yi와 예측값 H(xi)의 오차를 나타내는 함수라고 할 때, 여기서 새로운 함수 f를 어떻게 정의하느냐에 따라서 가중치를 최소화하는 적절한 목적 함수가 완성된다. \n",
    "- 목적 함수는 전체 데이터에 대해서 어떤 함수 f의 값의 평균을 계산하고 있다. \n",
    "- 적절한 가중치를 찾기 위해서는 결과적으로 실제값과 예측값에 대한 오차를 줄여야 하므로 여기서 이 f는 비용 함수(cost function)라고 하겠다. 식을 다시 쓰면 아래와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "    J( W ) = \\frac{1}{n}\\sum_{i=1}^ncost(H(x^{(i)}),y^{(i)})\n",
    "\\end{equation*}\n",
    "\n",
    "- 시그모이드 함수는 0과 1사이의 y값을 반환한다. \n",
    "- 이는 실제값이 0일 때 y값이 1에 가까워지면 오차가 커지며 실제값이 1일 때 y값이 0에 가까워지면 오차가 커짐을 의미합니다. 그리고 이를 반영할 수 있는 함수는 로그 함수를 통해 표현이 가능합니다.\n",
    "\n",
    "\\begin{equation*}\n",
    "    if y = 1 \\rightarrow cost(H(X),y) = -\\log(H(X))\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "    if y = 0 \\rightarrow cost(H(X),y) = -\\log(1-H(X))\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- y의 실제값이 1일 때 −logH(x) 그래프를 사용하고 y의 실제값이 0일 때 −log(1−H(X)) 그래프를 사용해야 한다. \n",
    "- 위의 두 식을 그래프 상으로 표현하면 아래와 같습니다.\n",
    "\n",
    "![Alt text]( loss_function.png )\n",
    "\n",
    "- 실제값이 1일 때의 그래프를 파란색 선으로 표현하였으며, 실제값이 0일 때의 그래프를 빨간색 선으로 표현하였다. \n",
    "- 위의 그래프를 설명하면, 실제값이 1일 때, 예측값인 H(X)의 값이 1이면 오차가 0이므로 당연히 cost는 0이 됩니다.반면, 실제값이 1일 때, H(X)가 0으로 수렴하면 cost는 무한대로 발산합니다. 실제값이 0인 경우는 그 반대로 이해하면 됩니다. \n",
    "- 이는 다음과 같이 하나의 식으로 표현할 수 있다.\n",
    "\n",
    "\\begin{equation*}\n",
    "    cost( H(X),y ) = -[ y \\log H(X) + ( 1 - y )\\log ( 1 - H(X) ) ]\n",
    "\\end{equation*}\n",
    "\n",
    "- 자세히 보면 y와 (1−y)가 식 중간에 들어갔고, 두 개의 식을 -로 묶은 것 외에는 기존의 두 식이 들어가있는 것을 볼 수 있다. \n",
    "- y가 0이면 ylogH(X)가 없어지고, y가 1이면 (1−y)log(1−H(X))가 없어지는데 이는 각각 y가 1일 때와 y가 0일 때의 앞서 본 식과 동일하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결과적으로 로지스틱 회귀의 목적 함수는 아래와 같다.\n",
    "\n",
    "\\begin{equation*}\n",
    "    J( W ) = -\\frac{1}{n}\\sum_{i=1}^n[y^{(i)} \\log H(X^{(i)})) + ( 1 - y^{(i)}) )\\log ( 1 - H(X^{(i)})) ) ]\n",
    "\\end{equation*}\n",
    "\n",
    "- 이때 로지스틱 회귀에서 찾아낸 비용 함수를 크로스 엔트로피( Cross Entropy ) 함수라고 한다. \n",
    "- 즉, 결론적으로 로지스틱 회귀는 비용 함수로 크로스 엔트로피( Cross Entropy ) 함수를 사용하며, 가중치를 찾기 위해서 크로스 엔트로피( Cross Entropy ) 함수의 평균을 취한 함수를 사용한다. \n",
    "- 크로스 엔트로피 함수는 소프트맥스 회귀의 비용 함수이기도 하다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
