{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.데이터 분리( splitting Data )\n",
    "   - 머신러닝( 딥러닝 ) 모델에 데이터를 학습시키기 위해서는 데이터를 적절히 분리하는 작업이 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 지도학습( supervised Learning )\n",
    "\n",
    "- 지도학습의 훈련 데이터는 정답이 무엇인지 맞춰야 하는 '문제'에 해당되는 데이터와 레이블(lable)이라고 부르는 '정답'이 적혀있는 데이터로 구성되어 있다.\n",
    "- 예로 스팸 메일 분류기를 만들기 위한 데이터에 대한 메일 내용과 해당 메일이 정상 메일인지, 스팸 메일인지 적혀있는 레이블로 구성되어져 있다고 가정하고, 데이터는 20000개가 있다.\n",
    "\n",
    "|텍스트(메일내용)|레이블(스팸 여부)|\n",
    "|:---:|:---:|\n",
    "|당신에게 드리는 마지막 혜택!...|스팸 메일|\n",
    "|내일 뵐 수 있을지 확인 부탁..|정상 메일|\n",
    "|...|...|\n",
    "|(광고)멋있어질 수 있는...|스팸 메일|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기계를 통한 학습을 하기 위해서는 총 4개의 데이터셋으로 나눈다.\n",
    "- 우선 메일 내용이 담긴 첫 번째 열을 x에 저장한다.\n",
    "- 그리고 메일이 스팸인지 정상인지 정답이 적혀있는 두 번째 열을 y에 저장한다.\n",
    "- 이제 20000개의 x와 20000개의 y로 나누어졌다.\n",
    "\n",
    "\n",
    "- x와 y에 대해서 일부 데이터를 다시 분리한다.\n",
    "- 실제 학습에 사용할 데이터와 학습 후 생성된 모델에 대한 테스트를 위한 데이터로 분리한다.\n",
    "- 통상 학습용은 80%, 테스트용은 20% 비율로 나눈다.\n",
    "- 이번 예에서는 학습용으로 18000개, 테스트용으로 2000개를 나누었다 가정한다.\n",
    "- 이와 같은 데이터 분리시에도 x와 y의 맵핑(그륩화) 관계는 유지 하여야 한다.\n",
    "- 어떤 x(입력, 문제)에 대한 y(정답)인지 바로 찾을 수 있어야 한다.\n",
    "\n",
    "\n",
    "<훈련 데이터>   \n",
    "x_train : 학습용 데이터   \n",
    "y_train : 학습용 데이터에 대한 정답 데이터\n",
    "\n",
    "\n",
    "<테스트 데이터>   \n",
    "x_test : 테스트용 데이터   \n",
    "y_test : 테스트용 데이터에 대한 정답 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- x_train과  y_train에 대해서 학습을 수행한다.\n",
    "- 기계는 현 상태에서는 정답지인 y_train을 볼 수 있기 때문에 x_train을 보면서 메일 내용이 정상 메일인지 스팸 메일인지 확인하여 패턴(규칙)을 도출하는 과정을 수행하여 모델을 생성한다.\n",
    "- 학습이 모두 끝난 상태의 모델에 y_test는 보여주지 않고, x_test에 대해서 정답을 예측하게 한다.\n",
    "- 모델이 예측한 답과 실제 정답인 y_test를 비교하면서 모델이 정답을 얼마나 맞췄는지를 평가 하는데 이 수치가 모델의 정확도(accuracy)가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. x와 y분리\n",
    "- zip()함수는 동일한 개수를 가지는 시퀀스 자료형에서 각 순서에 등장하는 원소들끼리 묶어주는 역할을 한다.\n",
    "- 리스트 구성에서 zip()함수는 x와 y를 분리하는데 유용하다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 'b', 'c')\n",
      "(1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "x, y = zip(['a', 1], ['b', 2], ['c', 3])\n",
    "print( x )\n",
    "print( y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 'b', 'c')\n",
      "(1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "sequence = [['a', 1], ['b', 2], ['c', 3]]\n",
    "x, y = zip( *sequence )\n",
    "print( x )\n",
    "print( y )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 데이터프레임을 이용한 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [ [ '당신에게 드리는 마지막 혜택!...', 1 ],\n",
    "           [ '내일 뵐 수 있을지 확인 부탁..', 0 ], \n",
    "           [ '길동군, 잘 지내고 있나? 오랜만...', 0 ], \n",
    "           [ '(광고)AI로 주가를 예측할 수...', 1 ] ]\n",
    "columns = [ '메일 본문', '스팸 메일 유무']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>메일 본문</th>\n",
       "      <th>스팸 메일 유무</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>당신에게 드리는 마지막 혜택!...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>내일 뵐 수 있을지 확인 부탁..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>길동군, 잘 지내고 있나? 오랜만...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(광고)AI로 주가를 예측할 수...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   메일 본문  스팸 메일 유무\n",
       "0    당신에게 드리는 마지막 혜택!...         1\n",
       "1     내일 뵐 수 있을지 확인 부탁..         0\n",
       "2  길동군, 잘 지내고 있나? 오랜만...         0\n",
       "3   (광고)AI로 주가를 예측할 수...         1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame( values, columns = columns )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[ '메일 본문' ]\n",
    "y = df[ '스팸 메일 유무' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      당신에게 드리는 마지막 혜택!...\n",
      "1       내일 뵐 수 있을지 확인 부탁..\n",
      "2    길동군, 잘 지내고 있나? 오랜만...\n",
      "3     (광고)AI로 주가를 예측할 수...\n",
      "Name: 메일 본문, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    1\n",
      "Name: 스팸 메일 유무, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Numpy를 이용한 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]]\n"
     ]
    }
   ],
   "source": [
    "ar = np.arange( 0, 16 ).reshape( ( 4, 4 ) )\n",
    "print( ar )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2]\n",
      " [ 4  5  6]\n",
      " [ 8  9 10]\n",
      " [12 13 14]]\n"
     ]
    }
   ],
   "source": [
    "x = ar[ :, :3 ]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  7 11 15]\n"
     ]
    }
   ],
   "source": [
    "y = ar[ :, 3 ]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 테스트 데이터 분리\n",
    "   - x와 y가 분리된 데이터에 대해서 테스트 데이터를 분리하는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Scikit-Learn을 이용한 분리\n",
    "\n",
    "- 훈련(학습)데이터와 테스트 데이터를 유용하게 나눌 수 있는 하나의 방법\n",
    "- scikit-learn은 훈련(학습)데이터와 테스트용 데이터를 분리하게 해주는 train_test_split()함수를 지원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 1234 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x : 독립(설명)변수 데이터, 특성(feature), (배열이나 데이터프레임)   \n",
    "y : 종속(반응)변수 데이터, 레이블(lable)데이터   \n",
    "test_size : 테스트용 데이터의 개수를 지정한다. 1보다 작은 실수를 지정할 경우 비용을 나타낸다.   \n",
    "train_size : 훈련(학습)용 데이터의 개수를 지정한다. 1보다 작은 실수를 지정할 경우 비용을 나타낸다.   \n",
    "(test_size와 train_size 중 하나만 기재해도 가능)   \n",
    "random_state : 난수 seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  5,  6],\n",
       "       [ 8,  9, 10],\n",
       "       [12, 13, 14]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 11, 15])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]\n",
      " [8 9]]\n",
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "x, y = np.arange(10).reshape( ( 5, 2 ) ), range( 5 )\n",
    "print( x )\n",
    "print( list( y ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33, random_state = 1234 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3]\n",
      " [4 5]\n",
      " [6 7]]\n",
      "[[8 9]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[4, 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33, random_state = 1234 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3]\n",
      " [4 5]\n",
      " [6 7]]\n",
      "[[8 9]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[4, 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 수동으로 분리\n",
    "   - 데이터를 분리하는 방법중 하나인 수동으로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.arange(0, 24).reshape( ( 12, 2 ) ), range( 12 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1]\n",
      " [ 2  3]\n",
      " [ 4  5]\n",
      " [ 6  7]\n",
      " [ 8  9]\n",
      " [10 11]\n",
      " [12 13]\n",
      " [14 15]\n",
      " [16 17]\n",
      " [18 19]\n",
      " [20 21]\n",
      " [22 23]]\n",
      "range(0, 12)\n"
     ]
    }
   ],
   "source": [
    "print( x )\n",
    "print( y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 12)\n"
     ]
    }
   ],
   "source": [
    "print( y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "print( list( y ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터 개수와 테스트 데이터 개수를 정한다.\n",
    "# n_of_train은 훈련 데이터 개수, n_of_test는 테스터 데이터 개수\n",
    "n_of_train = int( len( x ) * 0.8 )\n",
    "n_of_test = int( len( x ) - n_of_train )\n",
    "print( n_of_train )\n",
    "print( n_of_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 주의할 점은 아직 훈련 데이터와 테스트 데이터를 나눈것이 아니고, 갯수만 정한것이다.\n",
    "- n_of_train을 len(x)*0.8로 구했듯이 n_of_test 또한 len(x) * 0.2로 계산하면 될 것 같으나 이경우 데이터에 누락값이 발생할 가능성이 있다.\n",
    "- 따라서 어느 한 쪽을 계산하고 그 값만큼 제외하는 방식으로 계산해야 누락값이 발생하지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제로 데이터를 나눌 때도 n_of_train 같이 하나의 변수만 사용하면 데이터 누락을 방지할 수 있다.\n",
    "x_test = x[ n_of_train: ] # 전체 데이터중 20%만큼 뒤의 데이터 저장\n",
    "y_test = y[ n_of_train: ]\n",
    "\n",
    "x_train = x[ :n_of_train ] # 전체 데이터중 80%만큼 앞의 데이터 저장\n",
    "y_train = y[ :n_of_train ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1]\n",
      " [ 2  3]\n",
      " [ 4  5]\n",
      " [ 6  7]\n",
      " [ 8  9]\n",
      " [10 11]\n",
      " [12 13]\n",
      " [14 15]\n",
      " [16 17]]\n",
      "range(0, 9)\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18 19]\n",
      " [20 21]\n",
      " [22 23]]\n",
      "range(9, 12)\n"
     ]
    }
   ],
   "source": [
    "print(x_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 머신러닝 모델 평가\n",
    "<!-- ![alt text]( data.png ) -->\n",
    "<img src = \"data.png\" width = \"800\">\n",
    "   - 실제 모델을 평가하기 위해서 데이터를 훈령용, 검증용, 테스트용 이렇게 세가지로 분리하는 것이 일반적이다.\n",
    "   \n",
    "   \n",
    "   - 검증용 데이터는 모델의 성능을 평가하기 위한 용도가 아니라, 모델의 성능을 조정하기 위한 용도이다. 과적합이 되고 있는지 판단하거나 하이퍼파라미터의 조정을 위한 용도이다\n",
    "   \n",
    "   \n",
    "   - 하이퍼파라미터(초매개변수)란 값에 따라서 모델의 성능에 영향을 주는 매개변수들을 말한다. 가중치와 편향과 같은 학습을 통해 바뀌어져가는 변수는 매개변수라 한다.\n",
    "   \n",
    "   \n",
    "   - 하이퍼파라미터는 보통 사용자가 직접 정해줄 수 있는 변수로 머신러닝에서는 경사하강법에서의 학습률(learning rate)이 해당되고, 딥러닝에서는 은닉층의 수, 뉴런의 수, 드롭아웃 비율 등이 이에 해당한다. 매개변수는 사용자가 결정해주는 값이 아니라 모델이 학습하는 과정에서 얻어지는 값이다.\n",
    "   \n",
    "   \n",
    "   - 정리하면 하이퍼파라미터는 사람이 정하는 변수, 매개변수는 모델이 훈련을 통해서 바꾸는 변수이다.\n",
    "   \n",
    "   \n",
    "   - 훈련용 데이터로 훈련을 모두 시킨 모델은 검증용 데이터를 사용하여 정확도를 검증하며 하이퍼파라미터를 튜닝한다. 또한 이 모델의 매개변수는 검증용 데이터로 정확도가 검증되는 과정에서 점차 검증용 데이터에 점점 맞추어져 가기 시작한다.\n",
    "   \n",
    "   \n",
    "   - 하이퍼파라미터 튜닝이 끝났다면, 이제 검증용 데이터로 모델을 평가하는 것은 적합하지 않다.\n",
    "   \n",
    "   \n",
    "   - 모델에 대한 평가는 모델이 아직까지 보지 못한 데이터로 하는 것이 가장 바람직하다. 검증이 끝났다면 테스트 데이터를 가지고 모델의 진짜 성능을 평가한다.\n",
    "   \n",
    "   \n",
    "   - 검증 데이터와 테스트 데이터를 나눌 만큼 데이터가 충분하지 않다면 k-폴드 교차 검증이라는 방법을 사용하기도 한다.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 선형회귀( Linear Regression ) 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시험 공부하는 시간을 늘릴수록 성적이 잘 나오고, 하루에 걷는 횟수를 늘릴수록 몸무게가 줄어들고, 집의 평수가 넓을수록 집의 매매가격이 비싼 경향이 있다.\n",
    "- 위와 같은 내용을 수학적으로 생각해보면 어떤 요인의 수치에 따라서 특정 요인의 수치가 영향을 받고 있다고 말할 수 있다.\n",
    "- 즉, 어떤 변수의 값에 따라서 특정 변수의 값이 영향을 받고 있다고 볼 수 있다. 다른 변수의 값을 변하게 하는 변수를 x, 변수 x에 의해서 값이 종속적으로 변하는 변수 y라 할 때 변수 x의 값은 독립적으로 변할 수 있는 것에 반해, y값은 계속해서 x의 값에 의해서 종속적으로 결정되므로 x를 독립(설명) 변수, y를 종속(반응)변수라고 한다.\n",
    "- 선형회귀( Linear Regression )는 한 개 이상의 독립 변수와 x와 y의 선형 관계를 모델링한다. 만약 독립 변수 x가 1개라면 단순 선형 회귀라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 단순 선형 회귀 분석( Simple Linear Regrsseion Analysis )\n",
    "\n",
    "\\begin{equation*}\n",
    "    y = Wx + b\n",
    "\\end{equation*}\n",
    "\n",
    "- 단순 선형 회귀의 수식\n",
    "- 독립 변수 x와 곱해지는 값 W를 머신 러닝에서는 가중치(Weight), 별도로 더해지는 값 b를 편향(bias)라고 한다. 직선의 방정식에서는 각각 가중치를 직선의 기울기, 편향이 절편을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 다중 선형 회귀 분석( Multiple Linear Regression Analysis )\n",
    "\n",
    "\\begin{equation*}\n",
    "    y = W_1x_1 + W_2x_2 + ... + W_nx_n + b\n",
    "\\end{equation*}\n",
    "\n",
    "- 집의 매매 가격은 단순히 집의 평수가 넓다고 결정되는 게 아니라 집의 층수 방의 개수, 치하철 역과의 거리와도 영향이 있는 것 같다.\n",
    "- 다수의 요소를 가지고 집의 매매 가격을 예측하는 결우에 사용하는 회귀 분석\n",
    "- y는 1개 이지만 x는 1개 이상의 여러개가 활용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 가설( Hypothesis ) 세우기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 어떤 학생의 공부 시간에 따라서 다음과 같은 점수를 얻은 데이터가 있다.\n",
    "\n",
    "|hours( x )|score( y )|\n",
    "|:---:|:---:|\n",
    "|2|25|\n",
    "|3|50|\n",
    "|4|42|\n",
    "|5|61|\n",
    "\n",
    "![alt text]( hypothesis_1.png )\n",
    "\n",
    "\n",
    "- 알고 있는 데이터로부터 x와 y의 관계를 유추하고, 이 학생이 6시간, 7시간, 8시간을 공부하였을 때의 성적을 예측해보고 싶다.\n",
    "- x와 y의 관계를 유추하기 위해서 수학적으로 식을 세워보게 되는데 머신러닝에서는 이러한 식을 가설( Hypothesis )이라고 한다.\n",
    "\n",
    "\\begin{equation*}\n",
    "    H( x ) = Wx + b\n",
    "\\end{equation*}\n",
    "\n",
    "- H( x )에서 H는 Hypothesis를 의미하고, 위의 선형 회귀 가설은 이미 널리 알려져 있는 가설이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![alt text]( hypothesis_2.png )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위 그래프에서 W와 b의 값에 따라 천차만별로 그려지는 직선의모습을 볼 수 있다.\n",
    "- 가설 H( x )에서 W는 직선의 기울기이고 b는 절편으로 직선을 표현한다.\n",
    "- 결국 선형회귀는 주어진 데이터로부터 y와 x의 관계를 가장 잘 나타내는 직선을 그리는 일을 말한다.\n",
    "- 그리고 어떤 직선인지 결정하는 것은 W와 b의 값이므로 선형회귀에서 해야할 일은 결국 적절한 W와 b를 찾아내는 일이 된다.\n",
    "\n",
    "\n",
    "- 아직 방법은 모르지만 어떤 방법을 사용하여 적절한 W와 b의 값을 찾은 덕택에 y와 X의 관계를 가장 잘 나타내는 직선을 위의 그래프의 좌표 평면상에 그렸다고 가정했을때 이 직선을 X가 6일 때, 7일 때, 8일 때에 대해서도 계속해서 직선을 그저 이어그리면서 이 학생이 각각의 시간동안 공부한 시간에 따른 예상 점수를 알아낼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 비용 함수 (Cost Function ) : 평균 제곱 오차( MSE )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 가설( Hypothesis )은 주어진 데이터에서 x와 y의 관계를 W와 b를 이용하여 식을 세우는 일을 말한다.\n",
    "- 가설이 세워졌다면 이제 해야할 일은 문제에 대한 규칙을 가장 잘 표현하는 W와 b를 찾는 일이다.\n",
    "\n",
    "\n",
    "- 머신러닝은 W와 b를 찾기 위해서 실제값과 가설로부터 얻은 예측값의 오차를 계산하는 식을 세우고, 이 식의 값을 최소화 하는\n",
    "  최적의 W와 b를 찾아내야 한다.\n",
    "- 이 때 실제값과 예측값에 대한 오차에 대한 식을 목적함수( Object Function ) 또는 비용함수( Cost Funcyion ) 또는\n",
    "  손실함수( Loss Function )이라고 한다.\n",
    "- 함수의 값을 최소화하거나, 최대화하거나 하는 목적을 가진 함수를 목적함수( Object Function )이라 한다.\n",
    "- 그리고 값을 최소화하려고 하면 이를 비용함수( Cost Funcyion ) 또는 손실함수( Loss Function )라고 한다.\n",
    "\n",
    "\n",
    "- 비용함수는 단순히 실제값과 예측값에 대한 오차를 표현하면 되는 것이 아니라 예측값의 오차를 줄이는 일에 최적화된 식이어야 한다.\n",
    "- 회귀문제의 경우 주로 평균 제곱 오차( Mean Squared Error, MSE )가 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text]( cost_function.png )\n",
    "\n",
    "- 그래프에 임의의 W값이 13, 임의의 b값이 1을 가진 직선을 그렸다.\n",
    "- 임의로 그린 직선은 정답이 아니다.\n",
    "- 이제 이 직선으로부터 서서히 W와 b의 값을 바꾸면서 정답인 직선을 찾아내야한다.(오차의 크기가 최적화 된 선)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- y와 x의 관계를 가장 잘 나타내는 직선을 그린다는 것은 그래프에서 모든 점들과 위치적으로 가장 가까운 직선을 그리다는 것과 같다.\n",
    "- 오차(error) : 오차는 주어진 데이터에서 각 x에서의 실제값 y와 위의 직선에서 예측하고 있는 H( x )값의 차이를 말한다.\n",
    "- 그래프에서 위아래 화살표는 각 점에서 오차의 크기를 보여준다.\n",
    "- 오차를 줄여 가면서 W와 b의 값을 찾아내기 위해서는 전체 오차의 크기를 구해야 한다.\n",
    "- 오차의 크기를 측정하기 위한 가장 기본적인 방법은 각 오차를 모두 더하는 방법이 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- y = 13x + 1 직선이 예측한 예측값을 각각 실제값으로부터 오차를 계산한 결과는\n",
    "\n",
    "|hours( x )|2|3|4|5|\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|실제값|25|50|42|61|\n",
    "|예측값|27|40|53|66|\n",
    "|오차|-2|10|-11|-5|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 수식적으로 다순히 '오차 = 실제값 - 예측값' 이라고 정의한 후에 모든 오차를 더하면 음수 오차도 있고, 양수 오차도 있으므로 오차의 절대적인 크기를 구할 수 없다.\n",
    "- 그래서 모든 오차를 제곱하여 더하는 방법을 사용한다.\n",
    "- 그래프에서 모든 점과 직선 사이의 차이 거리를 제곱하고 모두 더한다.\n",
    "- 수식으로 표현하면( 단, 여기서 n은 갖고 있는 데이터의 개수를 의미한다. )\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\sum_{i=1}^n[y^{(i)} - H(x^{(i)})]^2 = (-2)^2 + 10^2 + (-7)^2 + (-5)^2 = 178\n",
    "\\end{equation*}\n",
    "\n",
    "시그마 = i가 1일 때 n까지 대입한 식을 다 더한 것 ( 𝑦(1)−𝐻(𝑥(1)) + 𝑦(2)−𝐻(𝑥(2)) +....𝑦(n)−𝐻(𝑥(n))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이때 데이터의 개수인 n으로 나누면, 오차의 제곱함에 대한 평균을 구할 수 있는데 이를 평균 제곱 오차( Mean Squared Error, MSE )\n",
    "  라고 한다.\n",
    "  \n",
    "\\begin{equation*}\n",
    "    \\frac{1}{n}\\sum_{i=1}^n[y^{(i)} - H(x^{(i)})]^2 = 178 / 4 = 44.5\n",
    "\\end{equation*}\n",
    "\n",
    "- y = 13x + 1 의 예측값과 실제값의 평균 제곱 오차의 값은 44.5이다. 평균 제곱 오차의 값을 최소값으로 만드는 W와 b를 찾아내는 것이 정답인 직선을 찾아내는 일이다.\n",
    "\n",
    "- 위에 함수는 비용함수 = 비용함수 값이 최소화되는 것이 목적( 오차값 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 평균 제곱 오차를 W와 b에 의한 비용함수(Cost Function)로 재정의하면\n",
    "\n",
    "\\begin{equation*}\n",
    "    cost( W, b ) = \\frac{1}{n}\\sum_{i=1}^n[y^{(i)} - H(x^{(i)})]^2\n",
    "\\end{equation*}\n",
    "\n",
    "- 모든 점들과 오차가 클 수록 평균 제곱 오차는 커지며, 오차가 작아질 수록 평균 제곱 오차는 작아진다.\n",
    "- 그러므로 이 평균 제곱 오차, 즉 Cost( W, b )를 최소가 되게 만드는 W와 b를 구하면 결과적으로 y와 x의 관계를 가장 잘 나타내는 직선을 그릴 수 있다.\n",
    "\n",
    "\\begin{equation*}\n",
    "   W,b \\rightarrow minimize cost( W, b )\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 옵티마이저( Optimizer ) : 경사 하강법( Gradient  Descent ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 선형 회귀 모델을 포함한 수많은 머신러닝 학습은 결국 비용함수를 최소화 하는데 매개 변수인 W와 b를 찾기 위한 작업을 수행한다.\n",
    "- 이 떄 사용하는 알고리즘을 옵티마이저( Optimizer ) 또는 최적화 알고리즘이라고 부른다.\n",
    "- 옵티마이저를 통해 적절한 W와 b를 찾아내는 과정을 머신러닝에서 학습(training)이라고 부른다.\n",
    "- 선형 회귀 모델의 기본적인 옵티마이저는 경사 하강법(Gradient Descent)이다.\n",
    "- 옵티마이저란 W, b값을 결정해주는 과정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 경사 하강법을 이해하기 위해서는 cost와 기울기 W와의 관계를 이해해야한다.\n",
    "- W는 머신러닝 용어로는 가중치라고 불리지만, 직선의 방정식 관점에서 보면 직선의 기울기를 의미한다.\n",
    "- 다음 그래프에서 기울기 W가 지나치게 높거나, 낮을 때 어떻게 오차가 커지는가를 보여준다.\n",
    "\n",
    "![alt text]( w_line.png )\n",
    "\n",
    "- 이 그래프는 y= 13x + 1 직선보다도 오차값의 차이가 크다\n",
    "- 즉, 기울기가 지나치게 크면 실제값과  예측값의 오차가 커지고, 기울기가 지나치게 작아도 실제값과 오차가 커진다.\n",
    "- b값도 지나치게 크거나 작으면 오차가 커진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cost와 W의 관계 \n",
    "\n",
    "![alt text]( cost_1.png )\n",
    "\n",
    "- 기울기 W가 무한대로 커지면 커질수록 cost의 값 또한 무한대로 커지고, 반대로 기울기 W가 무한대로 작아져도 cost의 값은 무한대로 커진다.\n",
    "- 그래프에서 cost가 가장 작을 때는 볼록한 부분의 맨 아래 부분이다.\n",
    "- 옵티마이저란 볼록한 부분의 맨 아래 지점까지 끌어내리는 과정(역할)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기계가 해야할 일은 cost가 가장 최솟값을 가지게 하는 W를 찾는 일이므로\n",
    "\n",
    "![alt text]( cost_2.png )\n",
    "\n",
    "- 볼록한 부분의 맨 아래 부분의 W값을 찾아야 한다.\n",
    "- 기계는 임의의 랜덤값 W값을 정한 뒤에 점차 수정되는 과정을 보여준다. 그리고 이를 가능하게 하는 것이 경사 하강법(Gradient Descent)이다.\n",
    "- 경사 하강법은 한 점에서의 순간 변화율 또는 접선에서의 기울기의 개념을 사용한다.\n",
    "\n",
    "![alt text]( cost_3.png )\n",
    "\n",
    "- 위 그래프에서 초록색 선은 W가 임의의 값을 가지게 되는 네 가지 경우에 대해서 그래프 상으로 접선의 기울기를 보여준다.\n",
    "- 주목할 것은 맨 아래의 볼록한 부분으로 갈수록 접선의 기울기가 점차 작아진다는 점이다. 그리고 맨 아래의 볼록한 부분에서는 결국 접선의 기욿기가 0이 된다. 그래프 상으로는 초록색 화살표가 수평이 되는 지점이다.\n",
    "- 즉, cost가 최소화가 되는 지점은 접선의 기울기가 0이 되는 지점이며, 또한 미분한 값이 0이 되는 지점이다.(기울기가 0)\n",
    "- 머신러닝으로 이 과정을 훈련한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 경사 하강법( Gradient Descent )의 아이디어는 비용함수( cost function )를 미분하여 현재 W에서의 접선의 기울기를 구하고, 접선의 기울기가 낮은 방향으로 W의 값을 변경하고, 다시 미분하고 이 과정을 접선의 기울기가 0인 곳을 향해 W의 값을 변경하는 작업을 반복하는 것이다.\n",
    "- 비용함수( cost function )\n",
    "\n",
    "\\begin{equation*}\n",
    "    cost( W, b ) = \\frac{1}{n}\\sum_{i=1}^n[y^{(i)} - H(x^{(i)})]^2\n",
    "\\end{equation*}\n",
    "\n",
    "- 비용(cost)를 최소화하는 W를 구하기 위해 W를 업데이트하는 식\n",
    "\n",
    "\\begin{equation*}\n",
    "    W := W - \\alpha \\frac{\\mathrm{d}}{\\mathrm{d}w}cost(w)\n",
    "\\end{equation*}\n",
    "\n",
    "- 위의 식을 접선의 기울기가 0이 될 때까지 반복한다.\n",
    "- 현재 W에서의 접선의 기울기와 alpha와 곱한 값을 현재 W에서 빼서 새로운 W의 값으로 한다는 것을 의미한다. alpha는 여기서 학습률( learning rate )이라고 한다.\n",
    "- :=(정의라는 뜻, 정의)\n",
    "- d/dw 는 cost(W)라는 함수를 미분하는 식인데 여기서 w는 변수로 바뀔수 있는 거고 d/dw자체를 미분해주는 기호라고 알고있자, a는 학습률\n",
    "- 𝛼옆에 식이 cost(w)을 미분하는 식, a는 지정 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text]( cost_4.png )\n",
    "\n",
    "- 위 그래프는 접선의 기울기가 음수일 때, 0일 때, 양수일 때의 경우를 보여준다. 접선의 기울기가 음수일 때는 위의 최적화 수식이 다음과 같이 표현 할 수 있다.\n",
    "\n",
    "\\begin{equation*}\n",
    "    W := W - \\alpha(음수기울기) = W - \\alpha(양수기울기)\n",
    "\\end{equation*}\n",
    "\n",
    "- 즉, 기울기가 음수면 W의 값이 증가하게 되는데 이는 결과적으로 접선의 기울기가 0인 방향으로 조정된다.\n",
    "- 만약 접선의 기울기가 양수라면 다음과 같이 수식을 표현할 수 있다.\n",
    "\n",
    "\\begin{equation*}\n",
    "    W := W - \\alpha(양수기울기)\n",
    "\\end{equation*}\n",
    "\n",
    "- 기울기가 양수면 W의 값이 감소하게 되는데 이는 결과적으로 기울기가 0인 방향으로 W의 값이 조정된다.\n",
    "\n",
    "\\begin{equation*}\n",
    "    W := W - \\alpha \\frac{\\mathrm{d}}{\\mathrm{d}w}cost(w)\n",
    "\\end{equation*}\n",
    "\n",
    "- 결국 위의 수식은 접선의 기울기가 음수거나, 양수일 때 모두 접선의 기울기가 0인 방향으로 W의 값을 조정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습률( learning rate ) alpha는 W의 값을 변경할 때, 얼마나 크게 변경할 지를 결정한다. 또는 W를 그래프의 한 점으로 보고 접선의 기울기가 0일 때까지 경사를 따라 내려간다는 관점에서는 얼마나 큰 폭으로 이동할 지를 결정한다.\n",
    "- 직관적으로 학습률 alpha의 값을 무작정 크게 하면 접선의 기울기가 최소값이 되는 W를 빠르게 찾을 수 있을 것 같지만 다음과 같은 현상이 발생할 수 있다.\n",
    "\n",
    "![alt text]( cost_5.png )\n",
    "\n",
    "- 학습률 alpha가 지나치게 높은 값을 가지면 접선의 기울기가 0이 되는 W를 찾아가는 것이 아니라 W의 값이 발산하는 상황이 될 수 있음을 그래프는 보여주고 있다.\n",
    "- 반대로 학습률 alpha가 지나치게 낮은 값을 가지면 학습 속도가 느려지므로 학습률 alpha를 찾아내는 것도 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경사 하강법은 W와 b를 동시에 경사 하강법을 수행하면서 최적의 W와 b의 값을 찾아간다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가설, 비용함수, 옵티마이저는 머신러닝 분야에서 포괄적으로 사용되는 개념이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀고자하는 각 문제에 따라 가설, 비용함수, 옵티마이저는 다를 수 있지만 선형 회귀에 가장 적합한 비용함수와 옵티마이저는 MSE와 경사 하강법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
