{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 ( Deep Learning ) 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여러 비선형 변환기법의 조합을 통해 높은 수준의 추상화( abstractions, 다량의 데이터나 복잡한 자료들 속에서 핵심적인 내용 또는 기능을 요약하는 작업)를 시도하는 기계학습( Machine Learning ) 알고리즘의 집합\n",
    "- 큰 틀에서 사람의 사고방식을 컴퓨터에게 가르치는 기계 학습의 한 분야\n",
    "- 영상처리, 음성처리, 자연어처리는 머신러닝보다 딥러닝이 더 우수함\n",
    "- 하지만 머신러닝에 비해 학습속도가 느리고 자원소모가 크기 때문에 모든 분야에 딥러닝을 적용하기엔 효율성이 떨어짐-> 때문에 gpu가 생김"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인공 신경망(Artificial Nueral Network )은 수많은 머신러닝중 하나이다. 하지만 최근 인공 신경망을 복잡하게 쌓아 올린 딥러닝이 다른 머신 러닝 방법들을 뛰어넘는 성능을 보여주는 사례가 늘면서, 전통적인 머신러닝과 딥 러닝을 구분해서 이해해야 한다는 의견도 있따.\n",
    "- 딥 러닝을 이해하기 우해서는 우선 인공 신경망에 대한 이해가 필요한데 초기 인공 신경망인 퍼셉트론( Perceptron )에 대한 이해가 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 퍼셉트론( Perceptron )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 퍼셉트론은 1957년에 프랑크 로젠블라트가 제안한 초기 형태의 인공 신경망이다.\n",
    "- 다수의 입력으로부터 하나의 결과를 내보내는 알고리즘이다.\n",
    "- 퍼셉트론은 실제 뇌를 구성하는 신경세포 뉴런의 동작과 유사하다.\n",
    "\n",
    "![Alt text]( neuron.png )\n",
    "\n",
    "- 뉴런은 가지돌기에서 신호를 받아들이고, 이 신호는 일정치 이상의 크기를 가지면 축삭돌기를 통해서 신호를 전달한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text]( perceptrin1_final.png )\n",
    "\n",
    "- 신경 세포는 뉴런의 입력 신호와 출력 신호가 퍼셉트론에서 각각 입력값과 출력값에 해당된다.\n",
    "- x는 입력값을 의미하고, W는 가중치, y는 출력값이다.\n",
    "- 그림에서 원은 인공뉴런에 해당한다.\n",
    "- 실제 신경 세포 뉴런에서의 신호를 전달하는 축삭돌기의 역할을 퍼셉트론에서는 가중치가 대신한다.\n",
    "- 각각의 인공 뉴런에서 보내진 입력값 x는 각각의 가중치 W와 함께 종착지인 인공 뉴런에 전달된다. \n",
    "- 각각의 입력값에는 각각의 가중치가 존재하는데 이 때 가중치의 값이 크면 클수록 해당 입력값이 중요하다는 것을 의미한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 입력값이 가중치와 곱해져서 인공 뉴런에 보내지고, 각 입력값과 그에 해당되는 가중치의 곱의 전체 합이 임게치를 넘으면 종착지에 있는 인공 뉴런은 출력 신호로서 1을 출력하고, 그렇지 않을 경우에는 0을 출력한다.\n",
    "- 이와 같이 0 또는 1을 출력하는 함수가 계단 함수( step function )이라고 한다.\n",
    "\n",
    "![Alt text]( step_function.png )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 계단 함수에 사용된 이 임계치값을 수식으로 표현할 때는 보통 세타로 표현한다.\n",
    "\n",
    "\\begin{equation*}\n",
    "    if\\sum_{i}^nW_ix_i \\geqq \\Theta \\rightarrow y = 1\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "    if\\sum_{i}^nW_ix_i < \\Theta \\rightarrow y = 1\n",
    "\\end{equation*}\n",
    "\n",
    "- 이 식에서 임계치를 좌변으로 넘기고 편향 b로 표현 할 수도 있다. 편향 b 또한 퍼셉트론의 입력으로 사용된다.\n",
    "\n",
    "![Alt text]( perceptron2_final.png )\n",
    "\n",
    "\\begin{equation*}\n",
    "    if\\sum_{i}^nW_ix_i + b \\geqq 0 \\rightarrow y = 1\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "    if\\sum_{i}^nW_ix_i + b < 0 \\rightarrow y = 0\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 뉴런에서 출력값을 변경시키는 함수를 활서오하 함수( Activation Function )이라고 한다.\n",
    "- 초기 인공 신경망 모델인 퍼셉트론은 활성화 함수로 계단 함수(step function)을 사용하였지만, 이 후 여러가지 발전된 신경망들은 계단 함수 외에도 여러 다양한 활성화 함수를 사용하기 시작하였다.\n",
    "- 시그모이드나 소프트맥스 함수 또한 활성화 함수 중 하나이다.\n",
    "- 퍼셉트론의 활성화 함수는 계단 함수이지만 활성화 함수를 시그모이드 함수로 변경하면 Logistic Rgression의 이진 분류( Binary Classification )를 수행한다.\n",
    "- 즉, 로지스틱 회귀 모델이 인공 신경망에서는 하나의 인공 뉴런으로 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단층 퍼셉트론( Single-Layer Perceptron )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 퍼셉트론은 단층 퍼셉트론과 다층 퍼셉트론으로 나뉜다.\n",
    "- 단층 퍼셉트론은 값을 보내는 단계와 값을 받아서 출력하는 두 단계로 이루어진다.\n",
    "- 각 단계를 보통 층(Layer)라고 부르며, 이 두 개의 층을 입력층과 출력층이라고 한다.\n",
    "\n",
    "![Alt text]( perceptron3_final.png )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단층 퍼셉트론을 이용하면, AND, OR, NAND 게이트를 쉽게 구현할 수 있다.\n",
    "- 게이트 연산에 쓰이는 것은 두 개의 입력값과 하나의 출력값이다.\n",
    "- AND 게이트의 경우 두 개의 입력 값이 모두 1인 경우만 출력값이 1이 나오는 구조이다.\n",
    "\n",
    "|x1|x2|y|\n",
    "|---:|---:|---:|\n",
    "|0|0|0|\n",
    "|0|1|0|\n",
    "|1|0|0|\n",
    "|1|1|1|\n",
    "\n",
    "- 단층 퍼셉트론의 식을 통해 AND 게이트를 만족하는 두 개의 가중치와 편향값을 각각 w1, w2, b라고 한다면 [ 0.5, 0.5, -0.7 ] 또는 [ 1.0, 1.0, -1.0 ] 등 이외에도 다양한 가중치와 편향의 조합이 나올 수 있다.(임의로 정할 수 있다, 가중치와 편향을)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " def AND_gate(x1, x2):\n",
    "        w1 = 0.5\n",
    "        w2 = 0.5\n",
    "        b = -0.7\n",
    "        result = x1 *w1 + x2 * w2 + b\n",
    "        \n",
    "        if result <= 0:\n",
    "            return 0 \n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AND_gate( 0, 0 ), AND_gate( 0, 1 ), AND_gate( 1, 0 ), AND_gate( 1, 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NAND 게이트의 경우 두 개의 입력 값이 1인 경우만 출력값이 0, 나머지 입력값의 쌍(Pair)에 대해서는 모두 출력값이 1이 나오는 구조이다.\n",
    "\n",
    "|x1|x2|y|\n",
    "|---:|---:|---:|\n",
    "|0|0|1|\n",
    "|0|1|1|\n",
    "|1|0|1|\n",
    "|1|1|0|\n",
    "\n",
    "- NAND 게이트를 만족하는 두 개의 가중치와 편향 값을 각각 w1, w2, b라고 한다면 [ 0.5, 0.5, -0.7 ] 또는 [ 1.0, 1.0, -1.0 ] 등 이외에도 다양한 가중치와 편향의 조합이 나올 수 있다.\n",
    "- NAND = NotAND 임 AND와 반대"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    " def NAND_gate(x1, x2):\n",
    "        w1 = -0.5\n",
    "        w2 = -0.5\n",
    "        b = 0.7\n",
    "        result = x1 *w1 + x2 * w2 + b\n",
    "        \n",
    "        if result <= 0:\n",
    "            return 0 \n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1, 0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAND_gate( 0, 0 ), NAND_gate( 0, 1 ), NAND_gate( 1, 0 ), NAND_gate( 1, 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OR 게이트의 경우 두 개의 입력 값이 0인 경우만 출력값이 0, 나머지 입력값의 쌍(Pair)에 대해서는 모두 출력값이 1이 나오는 구조이다.\n",
    "\n",
    "|x1|x2|y|\n",
    "|---:|---:|---:|\n",
    "|0|0|0|\n",
    "|0|1|1|\n",
    "|1|0|1|\n",
    "|1|1|1|\n",
    "\n",
    "- OR 게이트를 만족하는 두 개의 가중치와 편향 값을 각각 w1, w2, b라고 한다면 [ 0.6, 0.6, -0.5 ] 등 이외에도 다양한 가중치와 편향의 조합이 나올 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    " def OR_gate(x1, x2):\n",
    "        w1 = 0.6\n",
    "        w2 = 0.6\n",
    "        b = -0.5\n",
    "        result = x1 *w1 + x2 * w2 + b\n",
    "        \n",
    "        if result <= 0:\n",
    "            return 0 \n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 1, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OR_gate( 0, 0 ), OR_gate( 0, 1 ), OR_gate( 1, 0 ), OR_gate( 1, 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단층 퍼셉트론은 AND, OR, NAND 게이트에 대해서 구현이 가능하나 XOR 게이트에 대해서는 구현이 불가능하다.\n",
    "- XOR 게이트는 입력값 두 개가 서로 다른 값을 갖고 있을때에만 출력값이 1이 되고, 입력값 두개가 서로 같은 값을 갖면 출력값이 0이 되는 게이트이다.\n",
    "- 단층 퍼셉트론은 직선 하나로 두 영역을 나눌 수 있는 문제에 대해서만 구현이 가능하기 때문에 XOR 게이트는 단층 퍼셉트론의 가중치와 편향을 아무리 변경해도 구현 할 수 없다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AND 게이트에 대한 단층 퍼셉트론 시각화\n",
    "\n",
    "![Alt text]( andgraphgate.png )\n",
    "\n",
    "- 출력값 0을 하얀색 원, 1을 검은색 원으로 표현\n",
    "- AND 게이트를 충족하려면 하얀색 원과 검은색 원을 직선을 나누게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NAND 게이트와 OR 게이트에 대해서도 시각화 했을 때 직선으로 나누는 것이 가능하다.\n",
    "\n",
    "![Alt text]( oragateandnandgate.png )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XOR 게이트는 입력값 두 개가 서로 다른 값을 갖고 있을 때에만 출력값이 1이 되고, 입력값 두 개가 서로 같은 값을 가지면 출력값이 0이 되는 게이트이다.\n",
    "- XOR 게이트에 대한 단층 퍼셉트론 시각화\n",
    "\n",
    "![Alt text]( xorgraphandxorgate.png )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 하얀색, 원과 검은색 원을 직선 하나로 나누는 것이 불가능하다 (XOR 게이트 시각화)\n",
    "- 즉, 단층 퍼셉트론으로는 XOR 게이트를 구현하는 것이 불가능하다,\n",
    "- 이는 단층 퍼셉트론이 선형 영역에 대해서만 분리가 가능하다는 것을 말한다,\n",
    "- XOR 게이트는 직선이 아닌 곡선, 비선형 영역으로 분리하면 구현이 가능하다.\n",
    "\n",
    "![Alt text]( xorgate_nonlinearity.png )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다층 퍼셉트론( Multi-Layer Perceptron, MLP )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XOR 게이트는 기존의 AND, OR, NAND 게이트를 조합하면 만들 수 있다.\n",
    "- 퍼셉트론 관점에서 층을 더 쌓으면 만들 수 있다.\n",
    "- 다층 퍼셉트론과 단층 퍼셉트론의 차이는 단층 퍼셉트론은 입력층과 출력층만 존재하지만, 다층 퍼셉트론은 중간에 층을 더 추가하였다는 점이다.\n",
    "- 이와같이 입력층과 출력층 사이에 존재하는 층을 은닉층(Hiden Layer)이라 한다.\n",
    "- 즉, 다층 퍼셉트론은 입력층과 출력층 사이에 은닉층이 존재한다는 점이 단층 퍼셉트론과 다른 점이다.\n",
    "\n",
    "![Alt text]( perceptron_4image.png )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XOR_gate( x1, x2 ):\n",
    "    s1 = NAND_gate( x1, x2 )\n",
    "    s2 = OR_gate( x1, x2 )\n",
    "    y = AND_gate( s1, s2 )\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 1, 0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XOR_gate( 0, 0 ), XOR_gate( 0, 1 ), XOR_gate( 1, 0 ), XOR_gate( 1, 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XOR 예제에서는 은닉층을 1개만으로 문제를 해결할 수 있었지만, 다층 퍼셉트론은 본래 은닉층이 1개 이상인 퍼셉트론이다.\n",
    "- 즉, XOR 문제보다 더욱 복잡한 문제를 해결하기 위해서 다층 퍼셉트론은 중간에 수많은 은닉층을 더 추가할 수 있다.\n",
    "- 은닉층의 개수는 2개일 수도 있고, 수십 개일수도 있고 사용자가 설정하기 나름이다.\n",
    "- 다음은 더 어려운 문제를 풀기 위해서 은닉층이 하나 더 추가되고( 은닉층 2개 ), 뉴런의 개수를 늘린 다층 퍼셉트론이다.\n",
    " \n",
    "![Alt text]( DNN.png )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 은닉층이 2개 이상인 신경망을 심층 신경망( Deep Neural Network, DNN )이라고 한다. 2개 이하(1개)면 MLP라고 함\n",
    "- 심층 신경망은 다층 퍼셉트론만 이야기 하는 것이 아니라, 여러 변형된 다양한 신경망들도 은닉층이 2개 이상이 되면 심층 신경망이라고 한다.\n",
    "- AND, OR, NAND, XOR 게이트에서 퍼셉트론이 가야할 정답을 참고로 퍼셉트론이 정답을 출력할 때까지 가중치와 편향을 바꿔보면서 맞는 가중치와 편향을 결정하였다. 즉, 수동으로 가중치와 편향을 찾았다.\n",
    "- 하지만 기계가 가중치와 편향을 스스로 찾아내도록 자동화시켜야하는데 이것이 머신 러닝에서 말하는 학습 단계에 해당한다.\n",
    "- DNN을 이용한 학습 단계에서도 손실 함수( Loss Function )과 옵티마이저( Optimizer )를 사용한다.\n",
    "- 만약 학습을 시키는 인공 신경망이 심층 신경망일 경우에는 이를 심층 신경망을 학습시킨다고 하여, 딥 러닝(deep learning)이라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- p.383"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
